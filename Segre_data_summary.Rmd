---
title: "Segre_data_summary"
author: "Rosalee Elting"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(dplyr)
library(rstatix)
library(ggpubr)
library(rstan)
library(tidybayes)
```
# Load data 
```{r}
annas <- read_csv("annasairdata.csv")
head(annas)
```

# Cleaning Annas Data 
Only using data from a competition. 
Selecting data I am interested in from original data.

```{r}
annas_clean <- annas %>%
  filter(solocomp == "comp") %>%
  select(c("mass", "massSTD", "w.lifted", "w.liftedSTD", "wing.ar", "wing.arSTD", "wing.length", "wing.lengthSTD", "mean.hor_acel", "mean.hor_decel", "mean.arc_avghvel", "mean.total_vel", "ss.pitch_roll", "mean.pr_time", "mean.pr_degrees", "mean.arc_force", "PRTpercent"))

annas_mean <-  as.data.frame(annas_clean) %>%
  summarise(across(colnames(annas_clean), ~mean(.x, na.rm=TRUE))) %>%
  pivot_longer(cols = colnames(annas_clean)) %>%
  select(-c("name"))
annas_var <- as.data.frame(annas_clean) %>%
  summarise(across(colnames(annas_clean), ~var(.x, na.rm = TRUE))) %>%
  pivot_longer(cols = colnames(annas_clean)) %>%
  select(-c("name"))
 
annas_summ <- data.frame(matrix( NA, 
                                 ncol = 3, 
                                 nrow = 17))

names <- data.frame(rownames = colnames(annas_clean))

annas_summ[,1] <- names
annas_summ[,2] <- annas_mean
annas_summ[,3] <- annas_var
names(annas_summ) <- c("variable", "mean", "var")

```



# Using Loop to Visualize Original Data 

```{r}

x <- as.factor(0)
 viz <- annas_clean %>%
   cross_join(x, copy = TRUE)
 
 colNames <- names(viz)[1:17]
 
 for (i in colNames) {
   plot <- ggplot(viz, aes_string(x= viz$y, y = i))+ 
     geom_violin(draw_quantiles = c(0.25, 0.5, 0.75))+
     geom_point() +
     theme_classic()
  print(plot)
  Sys.sleep(2)
   
 }

```

# Using loop to check Orginial Data for Normality 
```{r}
normality_check <- as.data.frame(annas_clean)
columns <- names(normality_check)

for (i in columns) {
  plot <- hist(x = normality_check[,i])
  plot2 <- qqnorm(normality_check[,i]) 
    qqline(normality_check[,i])
  print(plot)
  print(plot2)
}
```

# Examining data distributions 

For each of the above distributions, I will group based on if the data is normal or otherwise distributed. Then using the mean and variance from annas_summ data frame, I will be able to establish fake data for this data set upon which to build a model. 
**The list of variables, in order, are below. This order corresponds with the order of plots from the above loop.**
 1. mass
 2. massSTD
 3. w.lifted         
 4. w.liftedSTD      
 5. wing.ar          
 6. wing.arSTD       
 7. wing.length     
 8. wing.lengthSTD   
 9. mean.hor_acel   
 10. mean.hor_decel   
 11. mean.arc_avghvel 
 12. mean.total_vel   
 13.ss.pitch_roll   
 14. mean.pr_time    
 15. mean.pr_degrees 
 16. mean.arc_force   
 17. PRTpercent
 
 **Proposed Distributions**
**Normal**
3. w.lifted         
  4. w.liftedSTD 
5. wing.ar - appears to increase at end, hard to tell but most close to normal    
    6. wing.arSTD 
7. wing.length     
  8. wing.lengthSTD
16. mean.arc_force   

**Beta**
 1. mass - skewed right 
  2. massSTD
 
9. mean.hor_acel - left-skewed data
10. mean.hor_decel   - left skewed data
11. mean.arc_avghvel - left skewed data
12. mean.total_vel  - left skewed data
13.ss.pitch_roll - right skewed  
14. mean.pr_time - right skwewed 
15. mean.pr_degrees - left skewed data
17. PRTpercent - left skewed

# Generating Fake Data 
For each variable, I will create a fake data set that has the same mean and variance, for 32 individuals and the distribution type seen above. 
 
## Data for variables with normal distribution 
column 3, weight lifted, w.lifted 
```{r}
w.lifted.simu <- rnorm(n =32, mean = annas_summ[1,2], sd= sqrt(annas_summ[1,3]))

plot(w.lifted.simu, col = "blue", ylim = c(3.5,7.5))
points(annas_clean$w.lifted, col = "red")
hist(w.lifted.simu)

```



# Moment matching for Beta Distributions 
Will do later with a loop through the data that are beta distributed, this is just for one data set for now: 
mean horizontal acceleration 
```{r}
mu <- annas_summ[9,2]
var <- annas_summ[9,3]

alpha <- mu*(mu*(1-mu)/var - 1)
beta <- (1-mu)*(mu*(1-mu)/var-1)

#generating fake data with these variables 
mean.hor_acel_simu <- rbeta(n=32, shape1 = -86.0668, shape2 = 73.074, ncp =0)
# This keeps generating NAs, so below I am running with some test data. 

y_rbeta <- rbeta(n=10000, shape1 = -86, shape2 = 73)
plot(density(y_rbeta))


```

I am having difficulty creating fake data sets with Beta distributions. For now, I am making a normally distributed fake data set for horizontal acceleration (variable 9) so that I can work on building a model around it, but need to come back to this distribution issue. 
```{r}

mean.hor_acel_simu <- rnorm(n =32, mean = annas_summ[9,2], sd= sqrt(annas_summ[9,3]))

plot(mean.hor_acel_simu, col = "blue", ylim = c(3.5,7.5))
points(annas_clean$mean.hor_acel, col = "red")
hist(mean.hor_acel_simu)
```
# Running Simple Linear Regression Stan Model with Simulated Data 
```{r}
annas_data_simu <- list(
      n = length(w.lifted.simu),
      mhoracel = as.numeric(mean.hor_acel_simu),
      wlifted = as.numeric(w.lifted.simu)
)

annas_fit <- stan(file = "annas_performance_model.stan", data = annas_data_simu, iter = 1000, chains = 4)
print(annas_fit)
```

# Visualizing and Summarizing Data 
```{r}
annas_fit_summ<- summary(annas_fit)

annas_data_simu <- data.frame(annas_data_simu)

mean_calc<- annas_data_simu %>%
  summarise(mean.hor_acel=mean(mhoracel), se=sd(mhoracel)/sqrt(32))

steps<- annas_fit_summ %>% 
#   spread_draws(a[n])
#   
# 
# ggplot(steps, aes(x=as.factor(site_id), y=mu_site)) + 
#   geom_violin()+
#   geom_boxplot(width=1, color="grey", alpha=0.2) +
#   geom_point(data=biomass_data, mapping = aes(x=as.factor(site_id), y=y ),  position = position_jitter(seed = 1, width = 0.1))+
#   geom_point(data=mean_calc, mapping = aes(x=as.factor(site_id), y=meanB), color= "#FF3300")+
#   xlab("Site")+
#   ylab("Bioamss")+
#   labs(title = "No Pooling")+
#   theme_classic()+
#   facet_wrap(.~site_id, nrow = 2)
```



# Segre Notes
Below are notes from this paper and things to consider when modeling 
•	Birds that lifted more weight (accounting for wing morph) accelerated and decelerated faster, and did maneuvers with higher velocity. 
o	Executed faster, larger radius arcing turns
o	Centripetal acceleration of arcing turns not associated with burst capacity. 
o	Pitch-roll turns in less time, and for more of their heading changes (proportionally) 
•	Aspect ratio was a predictor for: centripetal acceleration and percent direction changes that were pitch-roll-turns. 
•	Body mass not predict in models (overlapped with zero). 
•	Competitor didn’t have substantial effect on performance metrics 
o	Horizontal acceleration and deceleration affected in opposite direction than expected.
o	Pitch down velocity increased 
o	More arcing turns used. 
•	When wings are predictors, only shape not size matters. 
•	Aspect ratio predicted some maneuverability, only for some maneuvers. 
•	Burst capacity is a brief increase in muscle strain and velocity: ability to do this should increase foraging behavior and competitive ability. 
•	Use of arcing and pitch roll turns the only metric influenced by all morphology, burst muscle capacity and competitor presence. 



